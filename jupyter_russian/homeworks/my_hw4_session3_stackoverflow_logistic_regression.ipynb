{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "Автор материала: Павел Нестеров (@mephistopheies). Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.5.2\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.14.0\n",
      "scipy 1.0.0\n",
      "pandas 0.22.0\n",
      "matplotlib 2.1.1\n",
      "sklearn 0.19.0\n",
      "\n",
      "compiler   : GCC 5.4.0 20160609\n",
      "system     : Linux\n",
      "release    : 4.4.0-62-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 6\n",
      "interpreter: 64bit\n",
      "Git hash   : 26d92cab80e4fe897291a522ecca94ce8e89562e\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = '../../data/stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = '../../data/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'html', 'javascript', 'android', 'java', 'c++', 'jquery', 'c#', 'php', 'ios', 'python'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} \\\\\n",
    "&=& \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\vec{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\vec{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} \\\\\n",
    "&=& \\sigma_k\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\vec{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\vec{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\vec{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font>В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                #print(\" len %d\", len(sentence))\n",
    "                #print(\" sentence \", sentence)\n",
    "                \n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = 0\n",
    "                    #self._w[tag][self._vocab['exception']]\n",
    "                    someMap = {}\n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        if word not in someMap:\n",
    "                            someMap[word] = 1\n",
    "                        else:\n",
    "                            someMap[word] = someMap[word] + 1\n",
    "                        z += self._w[tag][self._vocab[word]] * 1\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sigma = 1/(1 + np.exp(-z)) if z > -100 else 0\n",
    "                    #sigma = max(min(1/(1 + np.exp(z)), tolerance), tolerance)\n",
    "   # sigmiod = 1/(1+np.exp(-z)) if z>-100 else 0\n",
    "    # loss = np.log(sigmoid) if sigmiod > toleranse else np.log(toleranse)\n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    #sample_loss += np.log(1+np.exp(-sigma))\n",
    "                    #sample_loss = np.log(sigma) if sigma > tolerance else np.log(tolerance)          \n",
    "                    sample_loss += np.log(1+np.exp(-sigma)) if sigma > tolerance else np.log(tolerance)\n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = (y - sigma)*someMap[tag]\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375cdc3c633f4f6582762a8216a3e711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(DS_FILE_NAME,  header=None, names=['message'])\n",
    "df = read_table(DS_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(df['message'])\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = pd.read_csv(TAGS_FILE_NAME,  header=None, names=['tag']\n",
    "df['target'] = df['message'].apply(lambda t : tags.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(C=1, random_state=17,n_jobs=-1)\n",
    "logit.fit(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5f69773dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: -280.00\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. 19.74\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. 0.59\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.59\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. c# \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. php\n",
    "4. java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
